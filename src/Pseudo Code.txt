"""

"whwhwhhooo, ok, here we go, focus. Code. I will Code."
vrooooom, vroom vroom vroom vroom
"One success, 42 errors. I eat errors for breakfast"
ngngngngng
"breakfast, maybe I should have had breakfast? Oh brekky could be good for me- no no no no stay focussed! Code."
vroomvroomvroomvroomvroomvroomvroomvroom
"I'm faster than fast, Quicker than quick. I am Lightning!"

"""


### Step 1: Initialisation ###

Create ~1000 instances of D, development plans which are each a set of d - potential development locations

This set of D instances make up the initial parents0 set.

Each instance of D is evaluated against the performance functions (f_heat, f_flood etc.) and get a value F which is the sum of the performance functions, f.


### Step 2: Iteration ###

The parents_g will go through G generations in an iterative process, producing offspring_g in each generation.

A new set of parents_g+1 of the same size will be chosen from the best of the combined set of parents_g and offspring_g.

The new set of parents_g+1 is used for the next generation g+1


### Step 3: Evolutionary Operators ###

At each generation a series of evolutionary operators are applied to D in parents_g, to produce a new set of D to form the set offspring_g

All D have a small probability to undergo a crossover operation:
There is a probability for each D to swap some d with another D

All D that don't succeed with crossover get assigned a small probability to mutate: There is a probability for a d_ij in D to randomly change ij coordinates within specified bounds.

The new set of D make up offspring_g, which go to step 4.

After step 4, what remains of offspring_g is combined with parents_g, and these are sorted and narrowed down to the best in step 5.


### Step 4: Constraints and Evaluate ###
Before the D in offspring_g are evaluated against the objective functions, a constraint handling module ensures they are feasible against restrictions.

All d in D are checked against specified constraints. Each d has an ij pair of coordinates for its position in the grid. If that position is not available for development for some reason, the d is deleted from D.

The successful ij are assigned an l which can be found from a generated lookup table, to save time and computational power.

Each d is evaluated against the objective functions, and gets an integer result that is the sum of all objective function results, F

Each D gets an integer value result that is the sum of all d in D, F values.


### Step 5: Non-Dominated Sorting ###

The set parents_g+1 for the next generation will consist of the best from parents_g and offspring_g.

This combined set undergoes non-dominated sorting to produce a series of sets of N.
As each N is produced, it is removed from the unsorted set and the remaining are sorted again.

The new parents_g+1 is built with N_1, N_2, ... until the next N wont fit into the parents_g+1 set.

To determine which D in the next N will be used to fill parents_g+1, a crowding distance is used to distinguish which areas of the Pareto front are least represented.
 - It fills in the gaps


### Step 6: Outputs ###

"Once there have been G generations, we break out of the loop and take the final set of parents_g+1 as the output. this is then used to determine the Pareto-optimal sets between pairs of objectives"



### Pseudo f functions ###

f_tsu:
if in, add 1

f_liq:
if TC [1 2 3], add [0.1, 1, 10]
if liq unlikely, add 0.1
if assessment needed, add 0.1?

f_cflood:
if in a coastal flood zone, add x depending on slr scenario (exponential decay from slr0 to slr300)

f_rflood:
if in a river flood zone, add 1

f_dist:
normalised distance from cbd, linear function.

f_dev:
if greenfield, add 1
